[[programming]]
== Programmer's Guide

Performant vector code on Saturn is generally not challenging to write and requires less microarchitectural fine-tuning than other vector or SIMD systems.
Still, some general guidelines for vector programming apply.
This guide focuses primarily on maximizing the performance of kernels based on FMA and MAC-type operations that map to Saturn's SIMD functional units.

//This guide aims to provide general guidance on writing performant vector code for Saturn.
//This guide is not meant to document typical performance programming techniques as those are covered extensively elsewhere, but we will include some of these details where useful.
//It is useful to first understand the Saturn microarchitecture as described in the other sections of this document before reviewing this guide.

=== Saturn Guidelines

Saturn's implementation is built around the machine datapath width, `DLEN`.
The fundamental occupancy of one vector instruction, or chime length, in a given Saturn implementation is `VLEN/DLEN`.
In most implementations, this will be 2, although Saturn can generate implementations with a chime length of 1 or greater.
Using the `LMUL` parameter allows the programmer to extend the chime length to `LMUL x VLEN/DLEN`, which increases the effective occupancy of each vector instruction.

Generally speaking, "writing efficient vector code" is equivalent to "maximizing the utilization of the functional units."
Saturn efficiently implements vector register grouping, and thus programmers should generally use the largest possible LMUL that applications allow without causing excessive vector register spilling.
By maximizing the `LMUL`, more work is encoded in each vector instruction and fewer iterations of a given stripmine loop will need to be executed.

Saturn implements vector chaining, which operates at a `DLEN` granularity.
Thus, a dependent vector operation that is buffered in a different sequencer may begin executing as soon as the first operation writes its first element group, assuming there are no other hazards.
This should be used to schedule code for Saturn.
For example, arithmetic operations may chain off of memory operations and vice-versa.
When using a configuration with multiple execute sequencers, independent arithmetic operations may chain off each other and overlap execution.

It is also important to take the pipeline depths of the various functional units into account.
For instance, the FMA functional units have a default pipeline depth of 4.
In order to saturate the FMA units, either the chime length must exceed the pipeline depth or a sufficient number of independent FMAs must be scheduled to hide this latency.

=== Microarchitecture Parameters

Refer to the xref:design-space.adoc[Design Space] section for more background on this topic.

The configuration sequencers and depth of issue queues is parameterized.
The number and type of sequencers will determine what kind of operations can run concurrently in Saturn.
For instance, if there is just a single execute sequencer, then all vector arithmetic operations will execute on that sequencer.
Thus, if a kernel requires multiple types of vector arithmetic operations, the machine will not be able to execute them concurrently.
If the Saturn instance has multiple execute sequencers in the "Split" or "Shared" configuration, Saturn will be able execute floating-point and integer instructions in parallel.

The issue queues buffer vector operations behind each sequencer after leaving the VDQ.
If too many successive vector instructions target a single sequencer, the instructions will saturate that sequences issue queue and backpressure dispatch, potentially resulting in a frontend stall, or starving other sequencers.
This should be avoided by scheduling instructions to naturally load-balance across the sequencers.
Shallow 2-4 entry issue-queues are typically enough to ameliorate issues from poor load-balancing.

=== Scalar Core

Saturn is designed to be performant even when integrated with a compact, single-issue, in-order scalar core.
Specific details related to Rocket and Shuttle can be found in xref:frontend.adoc[Frontend].
When writing loops, it is important to schedule scalar bookkeeping instructions such that they can overlap with the execution of the vector instructions.
Saturn configurations with short chime lengths are preferably integrated with Shuttle, as short-chime instructions generally require higher frontend instruction throughput.
When operating on long vector lengths with long chimes, we find the performance difference is mostly negligible between Rocket and Shuttle.

=== Static Scheduling

Saturn is designed to support efficient performance on vector length agnostic code that isn't optimized for a specific design point.
//This includes the precise scheduling mechanism that enables limited out-of-order execution of vector operations and the `DAE`-style implementation of the machine.
However, in many cases, some amount of static scheduling still provide some benefits, especially when the nature of the application becomes less favorable for dynamic hardware scheduling(eg. the application vector length becomes very short).
Configurations of Saturn which downsize the dynamic scheduling components, like the issue queues, further benefit from statically scheduled code.

//Similarly, as the chosen configuration of Saturn parameters becomes more minimal to save area or hardware complexity, more static scheduling may be required to acheive high performance.
Classic static scheduling techniques, such as loop unrolling and software pipelining, are all directly applicable to writing more performant vector code for Saturn, but in many cases may not be necessary.
Some examples can be found in https://github.com/ucb-bar/saturn-vector-impls/tree/master/benchmarks[benchmarks/].
//As application vector lengths become sufficiently long, it becomes simpler to saturate the machine with less extensive static scheduling and kernels can be reduced in size.

=== Complex  Instructions

Saturn's implementation strives to implement complex instructions efficiently.
As a general rule, using a complex instruction should never induce a performance penalty over the equivalent longer sequence of simpler instructions.
Thus, programmers should use complex instructions whereever possible, even if the kernel could be equivalently implemented by a sequence of simpler instructions.
//This has positive implications for performance and code size.
//As an example, programmers should make use of segment loads and stores where applicable, instead of using combinations of other instructions.

=== Other Notes

* Despite optimizations for other vector memory operations, aligned unit-stride operations will almost always be the most performant. Use them where possible.

* Reductions are far slower than independent vector operations. Avoid them where possible.

// === Performance Examples

// TODO demonstrate results with increasing levels of static scheduling, etc.
