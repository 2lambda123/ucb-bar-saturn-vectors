[[system]]
== System Overview and Organization

Saturn is organized into three main components.

* The *Vector Frontend (VFU)* integrates into the pipeline of a host RISC-V core.
In in-order cores, the stages of the VFU align with the pre-commit pipeline stages of the host core.
All vector instructions except `vset` instructions, are passed into the vector frontend.
The VFU performs early decode of vector instructions and checks vector instructions for the possibility of generating a trap, through performing address translation of vector memory address operands.
Instructions which do not trap are passed to the other vector components once they have also passed the commit stage of the scalar core.
* The *Vector Load-Store Unit (VLSU)* performs vector address generation and memory access.
Inflight vector memory instructions are tracked in the vector load-instruction-queue (VLIQ) and store-instruction-queue (VSIQ).
The V(L/S)IQs are used to check for both vector-vector and vector-scalar memory ordering hazards.
The load/store paths within the VLSU execute independently and communicate with the VU through load-response and store-data ports.
* The *Vector Datapath (VU)* contains instruction issue-queues (VIQs), vector sequencers (VXS/VLS/VSS), the vector register file (VRF, and the SIMD arithmetic functional units (VEUs/VFUs).
The sequencers schedule register read/write and operation issue into the VEUs, while interlocking on structural and data hazards.
The VU is organized as a unified structure, instead of distributing the VRF and VEUs across vector lanes.

We outline several key principles of Saturn's microarchitecture.

Saturn relies on *post-commit-execution* of all vector instructions.
That is, the VLSU and VU only receive committed instructions from the VFU.
As physical addresses are passed from the VFU into the VLSU, the VLSU will never trap.
This simplifies the microarchitecture of VLSU and VFUs, as all operations in these units are effectively non-speculative.

Saturn's microarchitecture is designed around *in-order execution* with many *latency-insensitive* interfaces.
Notably, the load and store paths are designed as pipelines of blocks with latency-insensitive decoupled interface.
The load-response and store-data interfaces into the VU are also latency-insensitive decoupled interfaces.
Within the VU, each execution path (load/store/arithmetic) execute instructions in-order.
The in-order execution of the load/store paths align with the in-order load-response and store-data ports.

Saturn is designed around a *decoupled access-execute (DAE)* architecture, where the VLSU acts as the "access processor" and the VU acts as the "execute processor".
Shallow instruction queues in the VU act as "decoupling" queues, and enable the VLSU's load-path to run many instructions ahead of the VU.
Similarly, the VLSU's store path can run many cycles beind the VU through the decoupling enabled by the VSIQ.
This approach can tolerate high memory latencies with minimal hardware cost.

Saturn still supports a limited, but sufficient capability for *out-of-order execution*.
The load, store, and execute paths in the VU execute independently with each other, dynamically interlocking for structural and data hazards without requiring full in-order execution.
Allowing dynamic "slip" between these paths naturally implies out-of-order execution.
To track data hazards, all vector instructions in the VU and VLSU are tagged with a "vector age tag (VAT)".
The VATs are aggressively allocated and freed, and referenced in the machine wherever wherever the relative age of two instructions is ambiguous.

To decode vector instructions, the Saturn generator implements an *instruction-database*-driven methodology for vector decode.
The Saturn generator tabularly describes a concise database of all vector control signals for all vector instructions.
Within the generator of the VU, control signals are extracted from the pipeline stages using a generator-time query into the instruction database.
The results from this query are used to construct a smaller decode table for only the relevant signals, which is passed to a logic minimizer in Chisel that generates that actual decode circuit.
This approach is used to reduce the prevalence of hand-designed decode circuits in the VU.
